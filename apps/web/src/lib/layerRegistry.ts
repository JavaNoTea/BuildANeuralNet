// src/lib/layerRegistry.ts
export interface LayerMeta {
  category: 'Layers' | 'Activations' | 'Pooling' | 'Normalization' | 'Loss' | 'Utility' | 'Input';
  friendly: string;
  torchClass: string;           // e.g. 'torch.nn.Conv2d'
  description: string;          // New field for helpful descriptions
  defaults: Record<string, any>;
  params: {
    name: string;
    type: 'int' | 'float' | 'bool' | 'select';   // drives form widgets
    options?: any[];                              // for select
    min?: number; max?: number;                   // for sliders
    required?: boolean;
  }[];
}

/** Mini sample â€• expand at will */
export const layerRegistry: LayerMeta[] = [
  // --- Input ---
  {
    category: 'Input',
    friendly: 'Dataset',
    torchClass: 'Dataset',
    description: 'Input dataset node providing data to the neural network. Represents the entry point for training and inference data. Connect this to the first layer of your model.',
    defaults: {},
    params: [],
  },
  // --- Layers ---
  {
    category: 'Layers',
    friendly: 'Linear',
    torchClass: 'torch.nn.Linear',
    description: 'Fully connected linear layer performing affine transformation: y = xW^T + b. Essential building block for feedforward networks, classification heads, and dense connections.',
    defaults: { in_features: 128, out_features: 64, bias: true },
    params: [
      { name: 'in_features', type: 'int', min: 1, required: true },
      { name: 'out_features', type: 'int', min: 1, required: true },
      { name: 'bias', type: 'bool' },
    ],
  },
  {
    category: 'Layers',
    friendly: 'Conv1d',
    torchClass: 'torch.nn.Conv1d',
    description: '1D convolution for sequential data like audio signals or time series. Applies convolution operation along one spatial dimension. Useful for signal processing and 1D pattern recognition.',
    defaults: { in_channels: 1, out_channels: 32, kernel_size: 3, stride: 1, padding: 0, dilation: 1, groups: 1, bias: true, padding_mode: 'zeros' },
    params: [
      { name: 'in_channels', type: 'int', min: 1, required: true },
      { name: 'out_channels', type: 'int', min: 1, required: true },
      { name: 'kernel_size', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'padding', type: 'int', min: 0 },
      { name: 'dilation', type: 'int', min: 1 },
      { name: 'groups', type: 'int', min: 1 },
      { name: 'bias', type: 'bool' },
      { name: 'padding_mode', type: 'select', options: ['zeros', 'reflect', 'replicate', 'circular'] },
    ],
  },
  {
    category: 'Layers',
    friendly: 'Conv2d',
    torchClass: 'torch.nn.Conv2d',
    description: '2D convolution for image processing. Applies 2D convolution over input signal with learnable filters. Core component of CNNs for feature extraction from spatial data.',
    defaults: { in_channels: 3, out_channels: 32, kernel_size: 3, stride: 1, padding: 0, dilation: 1, groups: 1, bias: true, padding_mode: 'zeros' },
    params: [
      { name: 'in_channels', type: 'int', min: 1, required: true },
      { name: 'out_channels', type: 'int', min: 1, required: true },
      { name: 'kernel_size', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'padding', type: 'int', min: 0 },
      { name: 'dilation', type: 'int', min: 1 },
      { name: 'groups', type: 'int', min: 1 },
      { name: 'bias', type: 'bool' },
      { name: 'padding_mode', type: 'select', options: ['zeros', 'reflect', 'replicate', 'circular'] },
    ],
  },
  {
    category: 'Layers',
    friendly: 'Conv3d',
    torchClass: 'torch.nn.Conv3d',
    description: '3D convolution for volumetric data like videos or medical scans. Applies 3D convolution over input signal. Useful for temporal-spatial feature extraction.',
    defaults: { in_channels: 3, out_channels: 32, kernel_size: 3, stride: 1, padding: 0, dilation: 1, groups: 1, bias: true, padding_mode: 'zeros' },
    params: [
      { name: 'in_channels', type: 'int', min: 1, required: true },
      { name: 'out_channels', type: 'int', min: 1, required: true },
      { name: 'kernel_size', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'padding', type: 'int', min: 0 },
      { name: 'dilation', type: 'int', min: 1 },
      { name: 'groups', type: 'int', min: 1 },
      { name: 'bias', type: 'bool' },
      { name: 'padding_mode', type: 'select', options: ['zeros', 'reflect', 'replicate', 'circular'] },
    ],
  },
  {
    category: 'Layers',
    friendly: 'Embedding',
    torchClass: 'torch.nn.Embedding',
    description: 'Embedding layer that maps discrete tokens to dense vector representations. Essential for NLP tasks to convert words/tokens into learnable dense vectors. Vocabulary size determines num_embeddings.',
    defaults: { num_embeddings: 1000, embedding_dim: 128, padding_idx: null, max_norm: null, norm_type: 2.0, scale_grad_by_freq: false, sparse: false },
    params: [
      { name: 'num_embeddings', type: 'int', min: 1, required: true },
      { name: 'embedding_dim', type: 'int', min: 1, required: true },
      { name: 'padding_idx', type: 'int', min: 0 },
      { name: 'max_norm', type: 'float', min: 0 },
      { name: 'norm_type', type: 'float', min: 0 },
      { name: 'scale_grad_by_freq', type: 'bool' },
      { name: 'sparse', type: 'bool' },
    ],
  },
  {
    category: 'Layers',
    friendly: 'LSTM',
    torchClass: 'torch.nn.LSTM',
    description: 'Long Short-Term Memory recurrent layer for sequential data. Excellent for handling long-term dependencies in sequences. Use for NLP, time series prediction, and sequential pattern recognition.',
    defaults: { input_size: 128, hidden_size: 64, num_layers: 1, bias: true, batch_first: false, dropout: 0.0, bidirectional: false },
    params: [
      { name: 'input_size', type: 'int', min: 1, required: true },
      { name: 'hidden_size', type: 'int', min: 1, required: true },
      { name: 'num_layers', type: 'int', min: 1 },
      { name: 'bias', type: 'bool' },
      { name: 'batch_first', type: 'bool' },
      { name: 'dropout', type: 'float', min: 0, max: 1 },
      { name: 'bidirectional', type: 'bool' },
    ],
  },
  {
    category: 'Layers',
    friendly: 'GRU',
    torchClass: 'torch.nn.GRU',
    description: 'Gated Recurrent Unit for sequential data processing. Simpler alternative to LSTM with fewer gates. Good balance between computational efficiency and sequence modeling capability.',
    defaults: { input_size: 128, hidden_size: 64, num_layers: 1, bias: true, batch_first: false, dropout: 0.0, bidirectional: false },
    params: [
      { name: 'input_size', type: 'int', min: 1, required: true },
      { name: 'hidden_size', type: 'int', min: 1, required: true },
      { name: 'num_layers', type: 'int', min: 1 },
      { name: 'bias', type: 'bool' },
      { name: 'batch_first', type: 'bool' },
      { name: 'dropout', type: 'float', min: 0, max: 1 },
      { name: 'bidirectional', type: 'bool' },
    ],
  },
  {
    category: 'Layers',
    friendly: 'RNN',
    torchClass: 'torch.nn.RNN',
    description: 'Basic Recurrent Neural Network layer for sequential data. Simple RNN with tanh or ReLU activation. Foundation for understanding recurrent architectures.',
    defaults: { input_size: 128, hidden_size: 64, num_layers: 1, nonlinearity: 'tanh', bias: true, batch_first: false, dropout: 0.0, bidirectional: false },
    params: [
      { name: 'input_size', type: 'int', min: 1, required: true },
      { name: 'hidden_size', type: 'int', min: 1, required: true },
      { name: 'num_layers', type: 'int', min: 1 },
      { name: 'nonlinearity', type: 'select', options: ['tanh', 'relu'] },
      { name: 'bias', type: 'bool' },
      { name: 'batch_first', type: 'bool' },
      { name: 'dropout', type: 'float', min: 0, max: 1 },
      { name: 'bidirectional', type: 'bool' },
    ],
  },
  {
    category: 'Layers',
    friendly: 'Flatten',
    torchClass: 'torch.nn.Flatten',
    description: 'Flattens input tensor into 1D while preserving batch dimension. Essential for transitioning from convolutional layers to fully connected layers in CNN architectures.',
    defaults: { start_dim: 1, end_dim: -1 },
    params: [
      { name: 'start_dim', type: 'int' },
      { name: 'end_dim', type: 'int' },
    ],
  },
  {
    category: 'Layers',
    friendly: 'ConvTranspose2d',
    torchClass: 'torch.nn.ConvTranspose2d',
    description: 'Transposed 2D convolution (deconvolution) for upsampling. Increases spatial dimensions. Essential for decoder networks, GANs, and segmentation models.',
    defaults: { in_channels: 64, out_channels: 32, kernel_size: 3, stride: 1, padding: 0, output_padding: 0, groups: 1, bias: true, dilation: 1, padding_mode: 'zeros' },
    params: [
      { name: 'in_channels', type: 'int', min: 1, required: true },
      { name: 'out_channels', type: 'int', min: 1, required: true },
      { name: 'kernel_size', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'padding', type: 'int', min: 0 },
      { name: 'output_padding', type: 'int', min: 0 },
      { name: 'groups', type: 'int', min: 1 },
      { name: 'bias', type: 'bool' },
      { name: 'dilation', type: 'int', min: 1 },
      { name: 'padding_mode', type: 'select', options: ['zeros', 'reflect', 'replicate', 'circular'] },
    ],
  },
  // --- Activations ---
  {
    category: 'Activations',
    friendly: 'ReLU',
    torchClass: 'torch.nn.ReLU',
    description: 'Rectified Linear Unit: max(0, x). Most widely used activation function. Solves vanishing gradient problem and provides computational efficiency. Default choice for hidden layers.',
    defaults: { inplace: false },
    params: [
      { name: 'inplace', type: 'bool' },
    ],
  },
  {
    category: 'Activations',
    friendly: 'LeakyReLU',
    torchClass: 'torch.nn.LeakyReLU',
    description: 'Leaky ReLU: max(0.01x, x). Addresses dying ReLU problem by allowing small negative values. Helps maintain gradient flow for negative inputs.',
    defaults: { negative_slope: 0.01, inplace: false },
    params: [
      { name: 'negative_slope', type: 'float' },
      { name: 'inplace', type: 'bool' },
    ],
  },
  {
    category: 'Activations',
    friendly: 'ELU',
    torchClass: 'torch.nn.ELU',
    description: 'Exponential Linear Unit: x if x>0, Î±(exp(x)-1) if xâ‰¤0. Smooth activation with mean closer to zero. Reduces bias shift and speeds up learning.',
    defaults: { alpha: 1.0, inplace: false },
    params: [
      { name: 'alpha', type: 'float' },
      { name: 'inplace', type: 'bool' },
    ],
  },
  {
    category: 'Activations',
    friendly: 'SELU',
    torchClass: 'torch.nn.SELU',
    description: 'Scaled Exponential Linear Unit. Self-normalizing activation function. Designed to maintain zero mean and unit variance. Use with proper weight initialization.',
    defaults: { inplace: false },
    params: [
      { name: 'inplace', type: 'bool' },
    ],
  },
  {
    category: 'Activations',
    friendly: 'GELU',
    torchClass: 'torch.nn.GELU',
    description: 'Gaussian Error Linear Unit. Smooth approximation to ReLU. Popular in transformer architectures. Provides probabilistic interpretation of activation.',
    defaults: { approximate: 'none' },
    params: [
      { name: 'approximate', type: 'select', options: ['none', 'tanh'] },
    ],
  },
  {
    category: 'Activations',
    friendly: 'Sigmoid',
    torchClass: 'torch.nn.Sigmoid',
    description: 'Sigmoid activation: 1/(1+exp(-x)). Maps input to (0,1) range. Commonly used for binary classification output and gating mechanisms in RNNs.',
    defaults: {},
    params: [],
  },
  {
    category: 'Activations',
    friendly: 'Tanh',
    torchClass: 'torch.nn.Tanh',
    description: 'Hyperbolic tangent: (exp(x)-exp(-x))/(exp(x)+exp(-x)). Maps input to (-1,1) range. Zero-centered output, preferred over sigmoid for hidden layers.',
    defaults: {},
    params: [],
  },
  {
    category: 'Activations',
    friendly: 'Softmax',
    torchClass: 'torch.nn.Softmax',
    description: 'Softmax activation for multi-class classification. Converts logits to probability distribution. Essential for converting raw scores to class probabilities.',
    defaults: { dim: null },
    params: [
      { name: 'dim', type: 'int' },
    ],
  },
  {
    category: 'Activations',
    friendly: 'Softplus',
    torchClass: 'torch.nn.Softplus',
    description: 'Softplus activation: log(1+exp(x)). Smooth approximation to ReLU. Always positive output, useful for modeling positive quantities.',
    defaults: { beta: 1, threshold: 20 },
    params: [
      { name: 'beta', type: 'float' },
      { name: 'threshold', type: 'float' },
    ],
  },
  {
    category: 'Activations',
    friendly: 'Softsign',
    torchClass: 'torch.nn.Softsign',
    description: 'Softsign activation: x/(1+|x|). Maps input to (-1,1) range. Polynomial convergence vs exponential for tanh. Useful alternative to tanh.',
    defaults: {},
    params: [],
  },
  {
    category: 'Activations',
    friendly: 'Hardtanh',
    torchClass: 'torch.nn.Hardtanh',
    description: 'Hard tanh activation: linear clipping. Computationally efficient alternative to tanh. Provides bounded output with linear regions.',
    defaults: { min_val: -1.0, max_val: 1.0, inplace: false },
    params: [
      { name: 'min_val', type: 'float' },
      { name: 'max_val', type: 'float' },
      { name: 'inplace', type: 'bool' },
    ],
  },
  // --- Pooling ---
  {
    category: 'Pooling',
    friendly: 'MaxPool1d',
    torchClass: 'torch.nn.MaxPool1d',
    description: '1D max pooling reduces spatial dimensions by taking maximum value in each pooling window. Provides translation invariance and reduces computational load. Use after Conv1d layers.',
    defaults: { kernel_size: 2, stride: null, padding: 0, dilation: 1, return_indices: false, ceil_mode: false },
    params: [
      { name: 'kernel_size', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'padding', type: 'int', min: 0 },
      { name: 'dilation', type: 'int', min: 1 },
      { name: 'return_indices', type: 'bool' },
      { name: 'ceil_mode', type: 'bool' },
    ],
  },
  {
    category: 'Pooling',
    friendly: 'MaxPool2d',
    torchClass: 'torch.nn.MaxPool2d',
    description: '2D max pooling for spatial dimension reduction in images. Takes maximum value in each pooling window. Provides translation invariance and computational efficiency.',
    defaults: { kernel_size: 2, stride: null, padding: 0, dilation: 1, return_indices: false, ceil_mode: false },
    params: [
      { name: 'kernel_size', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'padding', type: 'int', min: 0 },
      { name: 'dilation', type: 'int', min: 1 },
      { name: 'return_indices', type: 'bool' },
      { name: 'ceil_mode', type: 'bool' },
    ],
  },
  {
    category: 'Pooling',
    friendly: 'MaxPool3d',
    torchClass: 'torch.nn.MaxPool3d',
    description: '3D max pooling for volumetric data reduction. Takes maximum value in 3D pooling windows. Used in 3D CNNs for video or medical imaging.',
    defaults: { kernel_size: 2, stride: null, padding: 0, dilation: 1, return_indices: false, ceil_mode: false },
    params: [
      { name: 'kernel_size', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'padding', type: 'int', min: 0 },
      { name: 'dilation', type: 'int', min: 1 },
      { name: 'return_indices', type: 'bool' },
      { name: 'ceil_mode', type: 'bool' },
    ],
  },
  {
    category: 'Pooling',
    friendly: 'AvgPool1d',
    torchClass: 'torch.nn.AvgPool1d',
    description: '1D average pooling computes mean values in each pooling window. Smoother downsampling compared to max pooling. Preserves overall signal characteristics.',
    defaults: { kernel_size: 2, stride: null, padding: 0, ceil_mode: false, count_include_pad: true },
    params: [
      { name: 'kernel_size', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'padding', type: 'int', min: 0 },
      { name: 'ceil_mode', type: 'bool' },
      { name: 'count_include_pad', type: 'bool' },
    ],
  },
  {
    category: 'Pooling',
    friendly: 'AvgPool2d',
    torchClass: 'torch.nn.AvgPool2d',
    description: '2D average pooling computes spatial mean values. Smoother downsampling preserving spatial relationships. Alternative to max pooling for different feature characteristics.',
    defaults: { kernel_size: 2, stride: null, padding: 0, ceil_mode: false, count_include_pad: true, divisor_override: null },
    params: [
      { name: 'kernel_size', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'padding', type: 'int', min: 0 },
      { name: 'ceil_mode', type: 'bool' },
      { name: 'count_include_pad', type: 'bool' },
      { name: 'divisor_override', type: 'int', min: 1 },
    ],
  },
  {
    category: 'Pooling',
    friendly: 'AvgPool3d',
    torchClass: 'torch.nn.AvgPool3d',
    description: '3D average pooling for volumetric data. Computes mean in 3D windows. Provides smooth spatial-temporal downsampling for video or 3D medical data.',
    defaults: { kernel_size: 2, stride: null, padding: 0, ceil_mode: false, count_include_pad: true, divisor_override: null },
    params: [
      { name: 'kernel_size', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'padding', type: 'int', min: 0 },
      { name: 'ceil_mode', type: 'bool' },
      { name: 'count_include_pad', type: 'bool' },
      { name: 'divisor_override', type: 'int', min: 1 },
    ],
  },
  {
    category: 'Pooling',
    friendly: 'AdaptiveAvgPool2d',
    torchClass: 'torch.nn.AdaptiveAvgPool2d',
    description: 'Adaptive average pooling that outputs fixed-size regardless of input size. Essential for connecting variable-sized feature maps to fixed-size fully connected layers.',
    defaults: { output_size: 1 },
    params: [
      { name: 'output_size', type: 'int', min: 1, required: true },
    ],
  },
  {
    category: 'Pooling',
    friendly: 'AdaptiveMaxPool2d',
    torchClass: 'torch.nn.AdaptiveMaxPool2d',
    description: 'Adaptive max pooling that outputs fixed-size regardless of input size. Alternative to adaptive average pooling for extracting maximum activations.',
    defaults: { output_size: 1 },
    params: [
      { name: 'output_size', type: 'int', min: 1, required: true },
    ],
  },
  {
    category: 'Pooling',
    friendly: 'Upsample',
    torchClass: 'torch.nn.Upsample',
    description: 'Upsamples spatial dimensions using interpolation. Alternative to transposed convolution for increasing feature map size. Supports multiple interpolation modes.',
    defaults: { size: null, scale_factor: 2, mode: 'nearest', align_corners: null },
    params: [
      { name: 'scale_factor', type: 'float', min: 1 },
      { name: 'mode', type: 'select', options: ['nearest', 'linear', 'bilinear', 'bicubic', 'trilinear'] },
      { name: 'align_corners', type: 'bool' },
    ],
  },
  // --- Normalization ---
  {
    category: 'Normalization',
    friendly: 'BatchNorm1d',
    torchClass: 'torch.nn.BatchNorm1d',
    description: 'Normalizes features across batch dimension for 1D/2D input. Reduces internal covariate shift and enables higher learning rates. Essential for training stability in deep networks.',
    defaults: { num_features: 128, eps: 1e-5, momentum: 0.1, affine: true, track_running_stats: true },
    params: [
      { name: 'num_features', type: 'int', min: 1, required: true },
      { name: 'eps', type: 'float', min: 0 },
      { name: 'momentum', type: 'float', min: 0, max: 1 },
      { name: 'affine', type: 'bool' },
      { name: 'track_running_stats', type: 'bool' },
    ],
  },
  {
    category: 'Normalization',
    friendly: 'BatchNorm2d',
    torchClass: 'torch.nn.BatchNorm2d',
    description: 'Batch normalization for 2D spatial data (images). Normalizes across batch and spatial dimensions. Critical for stable training of deep convolutional networks.',
    defaults: { num_features: 64, eps: 1e-5, momentum: 0.1, affine: true, track_running_stats: true },
    params: [
      { name: 'num_features', type: 'int', min: 1, required: true },
      { name: 'eps', type: 'float', min: 0 },
      { name: 'momentum', type: 'float', min: 0, max: 1 },
      { name: 'affine', type: 'bool' },
      { name: 'track_running_stats', type: 'bool' },
    ],
  },
  {
    category: 'Normalization',
    friendly: 'LayerNorm',
    torchClass: 'torch.nn.LayerNorm',
    description: 'Normalizes features across feature dimension. Independent of batch size, making it suitable for RNNs and transformers. Computes statistics across the feature dimension.',
    defaults: { normalized_shape: 128, eps: 1e-5, elementwise_affine: true },
    params: [
      { name: 'normalized_shape', type: 'int', min: 1, required: true },
      { name: 'eps', type: 'float', min: 0 },
      { name: 'elementwise_affine', type: 'bool' },
    ],
  },
  {
    category: 'Normalization',
    friendly: 'GroupNorm',
    torchClass: 'torch.nn.GroupNorm',
    description: 'Group normalization divides channels into groups and normalizes within each group. Alternative to batch norm when batch sizes are small or variable.',
    defaults: { num_groups: 2, num_channels: 64, eps: 1e-5, affine: true },
    params: [
      { name: 'num_groups', type: 'int', min: 1, required: true },
      { name: 'num_channels', type: 'int', min: 1, required: true },
      { name: 'eps', type: 'float', min: 0 },
      { name: 'affine', type: 'bool' },
    ],
  },
  {
    category: 'Normalization',
    friendly: 'InstanceNorm2d',
    torchClass: 'torch.nn.InstanceNorm2d',
    description: 'Instance normalization for style transfer and domain adaptation. Normalizes across spatial dimensions per instance. Helps remove instance-specific contrast information.',
    defaults: { num_features: 64, eps: 1e-5, momentum: 0.1, affine: false, track_running_stats: false },
    params: [
      { name: 'num_features', type: 'int', min: 1, required: true },
      { name: 'eps', type: 'float', min: 0 },
      { name: 'momentum', type: 'float', min: 0, max: 1 },
      { name: 'affine', type: 'bool' },
      { name: 'track_running_stats', type: 'bool' },
    ],
  },
  // --- Loss ---
  {
    category: 'Loss',
    friendly: 'CrossEntropyLoss',
    torchClass: 'torch.nn.CrossEntropyLoss',
    description: 'Cross-entropy loss for multi-class classification. Combines LogSoftmax and NLLLoss. Use for classification tasks with mutually exclusive classes. Supports class weighting and label smoothing.',
    defaults: { weight: null, ignore_index: -100, reduction: 'mean', label_smoothing: 0.0 },
    params: [
      { name: 'ignore_index', type: 'int' },
      { name: 'reduction', type: 'select', options: ['none', 'mean', 'sum'] },
      { name: 'label_smoothing', type: 'float', min: 0, max: 1 },
    ],
  },
  {
    category: 'Loss',
    friendly: 'MSELoss',
    torchClass: 'torch.nn.MSELoss',
    description: 'Mean Squared Error loss for regression tasks. Computes squared difference between predictions and targets. Sensitive to outliers, provides smooth gradients.',
    defaults: { reduction: 'mean' },
    params: [
      { name: 'reduction', type: 'select', options: ['none', 'mean', 'sum'] },
    ],
  },
  {
    category: 'Loss',
    friendly: 'L1Loss',
    torchClass: 'torch.nn.L1Loss',
    description: 'L1 loss (Mean Absolute Error) for regression. Computes absolute difference between predictions and targets. More robust to outliers than MSE.',
    defaults: { reduction: 'mean' },
    params: [
      { name: 'reduction', type: 'select', options: ['none', 'mean', 'sum'] },
    ],
  },
  {
    category: 'Loss',
    friendly: 'BCEWithLogitsLoss',
    torchClass: 'torch.nn.BCEWithLogitsLoss',
    description: 'Binary cross-entropy loss with logits for binary classification. Combines sigmoid and BCE loss for numerical stability. Use for binary classification tasks.',
    defaults: { weight: null, reduction: 'mean', pos_weight: null },
    params: [
      { name: 'reduction', type: 'select', options: ['none', 'mean', 'sum'] },
    ],
  },
  // --- Utility ---
  {
    category: 'Utility',
    friendly: 'Add',
    torchClass: 'torch.add',
    description: 'Element-wise addition of two tensors. Essential for residual connections and skip connections in modern architectures like ResNet.',
    defaults: {},
    params: [],
  },
  {
    category: 'Utility',
    friendly: 'Concatenate',
    torchClass: 'torch.cat',
    description: 'Concatenates tensors along a specified dimension. Useful for combining features from different branches in complex architectures.',
    defaults: { dim: 1 },
    params: [
      { name: 'dim', type: 'int', required: true },
    ],
  },
  {
    category: 'Utility',
    friendly: 'ResNet Basic Block',
    torchClass: 'blocks.ResNetBasicBlock',
    description: 'ResNet basic block with two 3x3 convolutions, batch norm, and skip connection. Building block for ResNet-18 and ResNet-34 architectures.',
    defaults: { in_channels: 64, out_channels: 64, stride: 1, downsample: false },
    params: [
      { name: 'in_channels', type: 'int', min: 1, required: true },
      { name: 'out_channels', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'downsample', type: 'bool' },
    ],
  },
  {
    category: 'Utility',
    friendly: 'ResNet Bottleneck Block',
    torchClass: 'blocks.ResNetBottleneckBlock',
    description: 'ResNet bottleneck block with 1x1, 3x3, 1x1 convolutions. Building block for ResNet-50, ResNet-101, and ResNet-152 architectures.',
    defaults: { in_channels: 256, out_channels: 64, stride: 1, downsample: false },
    params: [
      { name: 'in_channels', type: 'int', min: 1, required: true },
      { name: 'out_channels', type: 'int', min: 1, required: true },
      { name: 'stride', type: 'int', min: 1 },
      { name: 'downsample', type: 'bool' },
    ],
  },
  {
    category: 'Utility',
    friendly: 'Inception Module',
    torchClass: 'blocks.InceptionModule',
    description: 'Inception module with parallel 1x1, 3x3, 5x5 convolutions and max pooling. Core building block for Inception/GoogLeNet architectures.',
    defaults: { in_channels: 192, out_1x1: 64, out_3x3_reduce: 96, out_3x3: 128, out_5x5_reduce: 16, out_5x5: 32, out_pool: 32 },
    params: [
      { name: 'in_channels', type: 'int', min: 1, required: true },
      { name: 'out_1x1', type: 'int', min: 1, required: true },
      { name: 'out_3x3_reduce', type: 'int', min: 1, required: true },
      { name: 'out_3x3', type: 'int', min: 1, required: true },
      { name: 'out_5x5_reduce', type: 'int', min: 1, required: true },
      { name: 'out_5x5', type: 'int', min: 1, required: true },
      { name: 'out_pool', type: 'int', min: 1, required: true },
    ],
  },
  {
    category: 'Utility',
    friendly: 'Dropout',
    torchClass: 'torch.nn.Dropout',
    description: 'Dropout regularization randomly sets elements to zero during training. Prevents overfitting by reducing co-adaptation of neurons. Essential regularization technique.',
    defaults: { p: 0.5, inplace: false },
    params: [
      { name: 'p', type: 'float', min: 0, max: 1 },
      { name: 'inplace', type: 'bool' },
    ],
  },
  {
    category: 'Utility',
    friendly: 'Identity',
    torchClass: 'torch.nn.Identity',
    description: 'Identity layer that returns input unchanged. Useful as placeholder in modular architectures or for debugging. No parameters or computation overhead.',
    defaults: {},
    params: [],
  },
];

